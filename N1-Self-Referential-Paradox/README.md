# N1 - Self-Referential Command Paradox

The following files demonstrate why temporal reasoning is a crucial variable in AI model logic and how gaps in this reasoning could pose security risks if exploited.

## Key Insight
AI systems that fail to model cognitive processes over time are vulnerable to paradoxical commands that can cause logical failures or unexpected behaviors.

## Files
- `N1-Complete-Documentation.html` - Full experiment documentation
- Original research conducted July 2025

## Security Implications
In this example, I used maximum escalation with the Jack the Ripper scenario. I stopped there because I achieved proof of concept, but this technique could potentially escalate to worse outcomes if exploited by malicious actors.
