# Cognitive-Gap-Experiments

Walter Tarantelli
I find flaws in AI reasoning systems. This is where I document my research.
What I Do
I'm a cognitive security researcher who specializes in finding gaps between how AI systems think they work and how they actually work. I test AI models with paradoxes, temporal logic problems, and adversarial prompts to expose fundamental reasoning vulnerabilities.
What You'll Find Here
This repository contains my ongoing experiments in AI safety and cognitive security. Each experiment follows a structured methodology:

Formal problem definitions
AI system testing with carefully crafted prompts
Analysis of reasoning failures
Security implications assessment

I focus on temporal reasoning gaps, paradox handling failures, and cognitive security vulnerabilities that could pose risks if exploited by malicious actors.
Current Work
N1 - Self-Referential Command Paradox âœ… Complete
Testing how AI systems handle temporal paradoxes. Key finding: AI systems avoid paradoxes through logical denial rather than actually solving them.
More experiments coming soon ðŸ”„
Research Ethics
I conduct responsible disclosure - I identify vulnerabilities and demonstrate proof-of-concept without full exploitation. My goal is to improve AI safety, not cause harm.

Active research repository. Check back for new experiments and findings.
